{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing of the dataset CORD-19\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the parser and parsing the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Parser import *\n",
    "from TaskQuery import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a Parser and specifying what kind of dataset we want to parse\n",
    "parser = Parser([Dataset.BIORXIV])\n",
    "parser.parse(indexByFile = False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of accesing the paper by index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can access the date by index or by file name, but we have to change in the parse function\n",
    "#what kind of invoke we want\n",
    "# print(parser.data_dicts[Dataset.BIORXIV][2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accesing certain elements of the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#By method titles(), abstracts() and bodies() you can access to certain elements of the paper\n",
    "# paper_abstracts = parser.titles()\n",
    "# for abstract in paper_abstracts[Dataset.BIORXIV].values():\n",
    "#     print(abstract)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#User manual\n",
    "#----------------------------------\n",
    "#Install --> pip3 install gensim (apart from gensim, you will need numpy)\n",
    "#Download word2vec file -->  https://code.google.com/archive/p/word2vec/\n",
    "import gensim.models.keyedvectors as word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we initialize word2vec with already pretrained vectors\n",
    "word2vec = word2vec.KeyedVectors.load_word2vec_format('data/GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('corona_virus', 0.7276226282119751),\n",
       " ('coronaviruses', 0.7216538190841675),\n",
       " ('paramyxovirus', 0.7113003730773926),\n",
       " ('SARS_coronavirus', 0.6601907014846802),\n",
       " ('arenavirus', 0.6494410037994385),\n",
       " ('influenza_virus', 0.6449826955795288),\n",
       " ('H#N#_subtype', 0.6360139846801758),\n",
       " ('H#N#_strain', 0.6324741840362549),\n",
       " ('H7_virus', 0.6261191964149475),\n",
       " ('flu_virus', 0.6249204874038696)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#As you can see, coronavirus is extremely similar with other virus terms \n",
    "word2vec.most_similar(\"coronavirus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#So word2vec is basically a dict, where for word it returns us a 300 dimensional vector. The more the words are similiar\n",
    "#so are the vectors going to be similar (talking here about cosine similarity!).\n",
    "# word2vec[\"cure\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doc2Vec demonstration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So, now we are heading into the big guns! Doc2Vec is basically word2vec, but only for words that are appearing in our dataset. Meaning that words like Coronavirus, Covid19, Wuhan and other important phrases will be recognized here by our model. In contrast, word2vec couldn't recognize covid19, because that's new term for this disease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here we are basically making our own dataset. We are taking our own papers ( parser.toList() will return all papers in dataset) and tagging them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_data = [TaggedDocument(words=word_tokenize(_d.lower()), tags=[str(i)]) for i, _d in enumerate(parser.toList())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is the training part. Here we are making our own word embeddings. That means we are basically going to make our own word2vec. In other words, for every word from our dataset our model will make a vector in 20 dimensional space. Furthermore, every vectors will be similar if the words they are representing are similar. E.g. vectors for word coronavirus and covid19 will be similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:15: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "max_epochs = 120\n",
    "vec_size = 20 #word2vec has 300, but I left 100 here\n",
    "alpha = 0.025\n",
    "\n",
    "d2v_model = Doc2Vec(vector_size=vec_size,\n",
    "                alpha=alpha, \n",
    "                min_alpha=0.00025,\n",
    "                min_count=1,\n",
    "                dm =1)\n",
    "\n",
    "d2v_model.build_vocab(tagged_data)\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    #print('iteration {0}'.format(epoch))\n",
    "    d2v_model.train(tagged_data,total_examples=d2v_model.corpus_count,epochs=d2v_model.iter)\n",
    "    # decrease the learning rate\n",
    "    d2v_model.alpha -= 0.0002\n",
    "    # fix the learning rate, no decay\n",
    "    d2v_model.min_alpha = d2v_model.alpha\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUERY >  Persistence of virus on surfaces of different materials\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "\n",
    "# query = TaskQuery.questions()[0]\n",
    "query = TaskQuery.topics()[5]\n",
    "\n",
    "print('QUERY > ', query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here we are testing our word embeddings with some query. Our query will be \"Coronavirus transmission\" and we are hoping to  find all the documents that are talking about coronavirus transmission. \n",
    "#### Here we are finding the embeddings that will correnspond with our query. Function most_similar() will return us id and percentage of similarity with corrensponding query. E.g. ('43', 0.834 ) means that document with id 43 is 83% similar with query. ( although this isn't really percentage, this is similarity, but thats the gist :) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('93', 0.7126882076263428), ('0', 0.6838240623474121), ('10', 0.668682336807251), ('20', 0.6443622708320618), ('96', 0.5813637971878052), ('67', 0.5454071760177612), ('26', 0.5204913020133972), ('91', 0.5128259658813477), ('89', 0.5120604038238525), ('16', 0.4907408654689789)]\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "#finding the most similar doc\n",
    "def d2v_most_similar(query):\n",
    "    test_data = word_tokenize(query.lower())\n",
    "    v1 = d2v_model.infer_vector(test_data)\n",
    "    return d2v_model.docvecs.most_similar([v1])\n",
    "    \n",
    "similar_docs = d2v_most_similar(query)\n",
    "print(similar_docs)\n",
    "print(len(similar_docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is the most similar document with our query within our dataset of 100 papers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(tagged_data[33])\n",
    "# print(parser.toList()[53])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language Modeling - NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize, sent_tokenize\n",
    "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
    "from nltk.lm import MLE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup for training of LM models and getting query relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lm_model(file, n_gram = 3):\n",
    "#     tokenized_text = [list(map(str.lower, word_tokenize(sent))) for sent in sent_tokenize(file)]\n",
    "    tokenized_text = []\n",
    "    for sent in sent_tokenize(file):\n",
    "        word_tokens = word_tokenize(sent) \n",
    "        filtered_sentence_tokens = [w.lower() for w in word_tokens if not w in set(stopwords.words('english'))] \n",
    "        tokenized_text.append(filtered_sentence_tokens)\n",
    "    train_data, padded_sents = padded_everygram_pipeline(n_gram, tokenized_text)\n",
    "    lm_model = MLE(n_gram)\n",
    "    lm_model.fit(train_data, padded_sents)\n",
    "    return lm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lm_query_relevance(model, sent):\n",
    "    return sum([ model.score(s) for s in list(map(str.lower, word_tokenize(sent))) ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Just a comparison for doc2vec's top 10 documents and the LM model scores they get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93 0.7126882076263428 0.0006792324673119375\n",
      "0 0.6838240623474121 0.0\n",
      "10 0.668682336807251 0.0003027550711474417\n",
      "20 0.6443622708320618 0.0013429373702844585\n",
      "96 0.5813637971878052 0.0005103776794828172\n",
      "67 0.5454071760177612 0.0\n",
      "26 0.5204913020133972 0.0\n",
      "91 0.5128259658813477 0.0010104412260020209\n",
      "89 0.5120604038238525 0.005164319248826291\n",
      "16 0.4907408654689789 0.00045330915684496827\n"
     ]
    }
   ],
   "source": [
    "for index, topic_sim in similar_docs:\n",
    "    lm_model = train_lm_model(parser.toList()[int(index)])\n",
    "    lm_score = lm_query_relevance(lm_model, query)\n",
    "    print(index, topic_sim, lm_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train LM models for the current parser documents (BIORXIV articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lm_most_similar(query, most_similar_count = 10):\n",
    "    scores = {}\n",
    "    for index, model in enumerate(lm_models):\n",
    "        scores[index] = lm_query_relevance(model, query)\n",
    "    return sorted(scores.items(), key=lambda x: x[1], reverse=True)[:most_similar_count]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mN_GRAM used > 1\u001b[0m\n",
      "QUERY >  \u001b[1mWhat range incubation periods disease humans ?\u001b[0m                                    |> matches count:4\n",
      "QUERY >  \u001b[1mWhat know basic reproduction number ?\u001b[0m                                             |> matches count:2\n",
      "QUERY >  \u001b[1mHow long individuals contagious ?\u001b[0m                                                 |> matches count:1\n",
      "QUERY >  \u001b[1mWhat know asymptomatic transmission children ?\u001b[0m                                    |> matches count:0\n",
      "QUERY >  \u001b[1mWhat know seasonality transmission ?\u001b[0m                                              |> matches count:3\n",
      "QUERY >  \u001b[1mWhat know viral shedding duration ?\u001b[0m                                               |> matches count:0\n",
      "QUERY >  \u001b[1mHow long individuals contagious , even recovery ?\u001b[0m                                 |> matches count:1\n",
      "QUERY >  \u001b[1mDoes range incubation period vary across age groups ?\u001b[0m                             |> matches count:2\n",
      "QUERY >  \u001b[1mDoes range incubation period vary children ?\u001b[0m                                      |> matches count:0\n",
      "QUERY >  \u001b[1mDoes range incubation period vary based underlying health ?\u001b[0m                       |> matches count:0\n",
      "QUERY >  \u001b[1mWhat prevalance asymptomatic transmission ?\u001b[0m                                       |> matches count:0\n",
      "Matches by n_gram:  \u001b[1m13\u001b[0m\n",
      "\u001b[1mN_GRAM used > 2\u001b[0m\n",
      "QUERY >  \u001b[1mWhat range incubation periods disease humans ?\u001b[0m                                    |> matches count:1\n",
      "QUERY >  \u001b[1mWhat know basic reproduction number ?\u001b[0m                                             |> matches count:2\n",
      "QUERY >  \u001b[1mHow long individuals contagious ?\u001b[0m                                                 |> matches count:0\n",
      "QUERY >  \u001b[1mWhat know asymptomatic transmission children ?\u001b[0m                                    |> matches count:0\n",
      "QUERY >  \u001b[1mWhat know seasonality transmission ?\u001b[0m                                              |> matches count:3\n",
      "QUERY >  \u001b[1mWhat know viral shedding duration ?\u001b[0m                                               |> matches count:0\n",
      "QUERY >  \u001b[1mHow long individuals contagious , even recovery ?\u001b[0m                                 |> matches count:1\n",
      "QUERY >  \u001b[1mDoes range incubation period vary across age groups ?\u001b[0m                             |> matches count:0\n",
      "QUERY >  \u001b[1mDoes range incubation period vary children ?\u001b[0m                                      |> matches count:0\n",
      "QUERY >  \u001b[1mDoes range incubation period vary based underlying health ?\u001b[0m                       |> matches count:0\n",
      "QUERY >  \u001b[1mWhat prevalance asymptomatic transmission ?\u001b[0m                                       |> matches count:0\n",
      "Matches by n_gram:  \u001b[1m7\u001b[0m\n",
      "\u001b[1mN_GRAM used > 3\u001b[0m\n",
      "QUERY >  \u001b[1mWhat range incubation periods disease humans ?\u001b[0m                                    |> matches count:2\n",
      "QUERY >  \u001b[1mWhat know basic reproduction number ?\u001b[0m                                             |> matches count:2\n",
      "QUERY >  \u001b[1mHow long individuals contagious ?\u001b[0m                                                 |> matches count:1\n",
      "QUERY >  \u001b[1mWhat know asymptomatic transmission children ?\u001b[0m                                    |> matches count:0\n",
      "QUERY >  \u001b[1mWhat know seasonality transmission ?\u001b[0m                                              |> matches count:3\n",
      "QUERY >  \u001b[1mWhat know viral shedding duration ?\u001b[0m                                               |> matches count:0\n",
      "QUERY >  \u001b[1mHow long individuals contagious , even recovery ?\u001b[0m                                 |> matches count:1\n",
      "QUERY >  \u001b[1mDoes range incubation period vary across age groups ?\u001b[0m                             |> matches count:0\n",
      "QUERY >  \u001b[1mDoes range incubation period vary children ?\u001b[0m                                      |> matches count:0\n",
      "QUERY >  \u001b[1mDoes range incubation period vary based underlying health ?\u001b[0m                       |> matches count:0\n",
      "QUERY >  \u001b[1mWhat prevalance asymptomatic transmission ?\u001b[0m                                       |> matches count:0\n",
      "Matches by n_gram:  \u001b[1m9\u001b[0m\n",
      "\u001b[1mN_GRAM used > 1\u001b[0m\n",
      "QUERY >  \u001b[1mRange incubation periods disease humans\u001b[0m                                           |> matches count:0\n",
      "QUERY >  \u001b[1mPrevalence asymptomatic shedding transmission\u001b[0m                                     |> matches count:0\n",
      "QUERY >  \u001b[1mSeasonality transmission\u001b[0m                                                          |> matches count:0\n",
      "QUERY >  \u001b[1mPhysical science coronavirus\u001b[0m                                                      |> matches count:0\n",
      "QUERY >  \u001b[1mPersistence stability multitude substrates sources\u001b[0m                                |> matches count:1\n",
      "QUERY >  \u001b[1mPersistence virus surfaces different materials\u001b[0m                                    |> matches count:1\n",
      "QUERY >  \u001b[1mNatural history virus shedding infected person\u001b[0m                                    |> matches count:4\n",
      "QUERY >  \u001b[1mImplementation diagnostics products improve clinical processes\u001b[0m                    |> matches count:5\n",
      "QUERY >  \u001b[1mDisease models , including animal models infection , disease transmission\u001b[0m         |> matches count:1\n",
      "QUERY >  \u001b[1mTools studies monitor phenotypic change potential adaptation virus\u001b[0m                |> matches count:2\n",
      "QUERY >  \u001b[1mImmune response immunity\u001b[0m                                                          |> matches count:0\n",
      "QUERY >  \u001b[1mEffectiveness personal protective equipment\u001b[0m                                       |> matches count:1\n",
      "QUERY >  \u001b[1mRole environment transmission\u001b[0m                                                     |> matches count:3\n",
      "Matches by n_gram:  \u001b[1m18\u001b[0m\n",
      "\u001b[1mN_GRAM used > 2\u001b[0m\n",
      "QUERY >  \u001b[1mRange incubation periods disease humans\u001b[0m                                           |> matches count:0\n",
      "QUERY >  \u001b[1mPrevalence asymptomatic shedding transmission\u001b[0m                                     |> matches count:0\n",
      "QUERY >  \u001b[1mSeasonality transmission\u001b[0m                                                          |> matches count:0\n",
      "QUERY >  \u001b[1mPhysical science coronavirus\u001b[0m                                                      |> matches count:0\n",
      "QUERY >  \u001b[1mPersistence stability multitude substrates sources\u001b[0m                                |> matches count:1\n",
      "QUERY >  \u001b[1mPersistence virus surfaces different materials\u001b[0m                                    |> matches count:1\n",
      "QUERY >  \u001b[1mNatural history virus shedding infected person\u001b[0m                                    |> matches count:4\n",
      "QUERY >  \u001b[1mImplementation diagnostics products improve clinical processes\u001b[0m                    |> matches count:3\n",
      "QUERY >  \u001b[1mDisease models , including animal models infection , disease transmission\u001b[0m         |> matches count:1\n",
      "QUERY >  \u001b[1mTools studies monitor phenotypic change potential adaptation virus\u001b[0m                |> matches count:2\n",
      "QUERY >  \u001b[1mImmune response immunity\u001b[0m                                                          |> matches count:0\n",
      "QUERY >  \u001b[1mEffectiveness personal protective equipment\u001b[0m                                       |> matches count:1\n",
      "QUERY >  \u001b[1mRole environment transmission\u001b[0m                                                     |> matches count:3\n",
      "Matches by n_gram:  \u001b[1m16\u001b[0m\n",
      "\u001b[1mN_GRAM used > 3\u001b[0m\n",
      "QUERY >  \u001b[1mRange incubation periods disease humans\u001b[0m                                           |> matches count:0\n",
      "QUERY >  \u001b[1mPrevalence asymptomatic shedding transmission\u001b[0m                                     |> matches count:0\n",
      "QUERY >  \u001b[1mSeasonality transmission\u001b[0m                                                          |> matches count:0\n",
      "QUERY >  \u001b[1mPhysical science coronavirus\u001b[0m                                                      |> matches count:0\n",
      "QUERY >  \u001b[1mPersistence stability multitude substrates sources\u001b[0m                                |> matches count:2\n",
      "QUERY >  \u001b[1mPersistence virus surfaces different materials\u001b[0m                                    |> matches count:0\n",
      "QUERY >  \u001b[1mNatural history virus shedding infected person\u001b[0m                                    |> matches count:4\n",
      "QUERY >  \u001b[1mImplementation diagnostics products improve clinical processes\u001b[0m                    |> matches count:1\n",
      "QUERY >  \u001b[1mDisease models , including animal models infection , disease transmission\u001b[0m         |> matches count:1\n",
      "QUERY >  \u001b[1mTools studies monitor phenotypic change potential adaptation virus\u001b[0m                |> matches count:2\n",
      "QUERY >  \u001b[1mImmune response immunity\u001b[0m                                                          |> matches count:0\n",
      "QUERY >  \u001b[1mEffectiveness personal protective equipment\u001b[0m                                       |> matches count:3\n",
      "QUERY >  \u001b[1mRole environment transmission\u001b[0m                                                     |> matches count:2\n",
      "Matches by n_gram:  \u001b[1m15\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def bold(data):\n",
    "    return Paper.bold(str(data))\n",
    "\n",
    "query_collections = [TaskQuery.questions(), TaskQuery.topics()]\n",
    "n_grams = [1, 2, 3]\n",
    "\n",
    "for collection in query_collections:\n",
    "    for n_gram in n_grams:\n",
    "        lm_models = [ train_lm_model(file, n_gram) for file in parser.toList() ]\n",
    "        print(Paper.bold('N_GRAM used > ' + str(n_gram)))\n",
    "        matches_by_n_gram = 0\n",
    "        for query in collection:\n",
    "            query = ' '.join([w for w in word_tokenize(query) if not w in set(stopwords.words('english'))])\n",
    "            lm_scores = [ score[0] for score in lm_most_similar(query) ]\n",
    "            d2v_scores = [ int(score[0]) for score in d2v_most_similar(query) ]\n",
    "            matches = list(set(lm_scores).intersection(d2v_scores))\n",
    "            matches_by_n_gram += len(matches)\n",
    "    #       FIRST OUTPUT - a lot of details\n",
    "    #         print('QUERY > ', bold(query))\n",
    "    #         print('Top 10 - LM')\n",
    "    #         print(lm_scores)\n",
    "    #         print('Top 10 - d2v')\n",
    "    #         print(d2v_scores)\n",
    "    #         print('Matches: ', bold(str(matches) + '\\n'))\n",
    "    #       SECOND OUTPUT - only match numbers\n",
    "            print('{:9}{:90}{}{}'.format('QUERY >', bold(query), '|> matches count:', (len(matches))))\n",
    "        print('Matches by n_gram: ', bold(matches_by_n_gram))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
